{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SuInput \u00b6 (Better name pending) SuInput is an input system designed to give pancake and XR applications access to a huge range of input devices while minimizing the amount of complexity needed to support them. This is achieved by applications creating abstract 'actions' with explicit names and types, and relying on SuInput to map these actions to real devices. This kind of system combined with other features that SuInput provides such as Input Glyphs and external configuration allows applications to have first class support for almost any human interface device, including those that didn't exist when it was written. SuInput is heavily inspired by Steam Input & OpenXR and borrows many of their concepts and naming conventions. SuInput has substantial differences from each of these systems to increase accessibility, ease of use, flexibility and stability. Github Repo Github Project API Types Summary SIAPI Issues \u00b6 Only supports modern console and generic controllers Confusing GUI Only offers primitive action types Undocumented edge cases Applications have to be published to Steam Closed source and inextensible Applications often botch their implementation of SIAPI / mixed input Applications cannot have their own rebinding menus OpenXR Issues \u00b6 Limited non-XR device support Limited remapping tools Only offers primitive action types and bindings (without extensions) Entirely polling based Undefined behaviour between runtimes Input is a small part of a much larger specification Applications cannot have their own rebinding menus Preventing these issues in SuInput \u00b6 SuInput intends to circumvent these flaws with strict key design philosophies: Make SuInput flexible enough to be able to make full use of the capabilities of almost any human interface device. From (analogue) keyboards, to Wiimotes, to Oculus Touch Controllers. Have a list of rules that applications must follow to make use of SuInput. These include not manually reading device input, treating action types in specific ways and using SuInput's input glyphs when told to. Offer a simple external mapping GUI for users to customize bindings without having to read the manual first. Offer a complex external mapping tool for power users so external re-mappers are not needed (such as Steam Input, ReWASD or JSM). Keep SuInput open and extensible so users and developers can add support for custom devices, action types and binding types. Currently there are no plans for SuInput to work as a desktop remapper, but there are plans for it to work as an OpenXR remapper since very few exist. There is no reason SuInput cannot be used as a desktop remapper and in future I may use it to make one with a pricing model similar to Aseprite and ReWASD to help fund development.","title":"SuInput"},{"location":"#suinput","text":"(Better name pending) SuInput is an input system designed to give pancake and XR applications access to a huge range of input devices while minimizing the amount of complexity needed to support them. This is achieved by applications creating abstract 'actions' with explicit names and types, and relying on SuInput to map these actions to real devices. This kind of system combined with other features that SuInput provides such as Input Glyphs and external configuration allows applications to have first class support for almost any human interface device, including those that didn't exist when it was written. SuInput is heavily inspired by Steam Input & OpenXR and borrows many of their concepts and naming conventions. SuInput has substantial differences from each of these systems to increase accessibility, ease of use, flexibility and stability. Github Repo Github Project API Types Summary","title":"SuInput"},{"location":"#siapi-issues","text":"Only supports modern console and generic controllers Confusing GUI Only offers primitive action types Undocumented edge cases Applications have to be published to Steam Closed source and inextensible Applications often botch their implementation of SIAPI / mixed input Applications cannot have their own rebinding menus","title":"SIAPI Issues"},{"location":"#openxr-issues","text":"Limited non-XR device support Limited remapping tools Only offers primitive action types and bindings (without extensions) Entirely polling based Undefined behaviour between runtimes Input is a small part of a much larger specification Applications cannot have their own rebinding menus","title":"OpenXR Issues"},{"location":"#preventing-these-issues-in-suinput","text":"SuInput intends to circumvent these flaws with strict key design philosophies: Make SuInput flexible enough to be able to make full use of the capabilities of almost any human interface device. From (analogue) keyboards, to Wiimotes, to Oculus Touch Controllers. Have a list of rules that applications must follow to make use of SuInput. These include not manually reading device input, treating action types in specific ways and using SuInput's input glyphs when told to. Offer a simple external mapping GUI for users to customize bindings without having to read the manual first. Offer a complex external mapping tool for power users so external re-mappers are not needed (such as Steam Input, ReWASD or JSM). Keep SuInput open and extensible so users and developers can add support for custom devices, action types and binding types. Currently there are no plans for SuInput to work as a desktop remapper, but there are plans for it to work as an OpenXR remapper since very few exist. There is no reason SuInput cannot be used as a desktop remapper and in future I may use it to make one with a pricing model similar to Aseprite and ReWASD to help fund development.","title":"Preventing these issues in SuInput"},{"location":"API%20Types%20Summary/","text":"Runtime \u00b6 An abstraction over either an embedded or external SuInput runtime and is used to create Instances. There should only be one of these per process. Instance \u00b6 Similar to Vulkan and OpenXR, an Instance is how applications accesses SuInput's API. Since there are already Runtime and Application Instance types it is possible that this abstraction is unnecessary however it could be useful if SuInput ever provides OpenXR-like extensions. Application \u00b6 The Application is a structure containing useful metadata about the application such as name and version. It is used by SuInput to group similar Application Instances together. Application Instance \u00b6 An Application Instance is an (optionally) persistent object containing all the required details about one specific install of an Application. On creation it takes some parameters which become immutable during it's Session's lifespan: - The base Application - Extra metadata specific to this application install - All the Static Action Sets the for the application - All the default Binding Layouts It also has these mutable members: - Dynamic Action Sets - Is installed predicate (Override how the external runtime checks if an app is still installed) Session \u00b6 An SuInput Session. Similar to OpenXR, a Session is the actual 'running' part of the application. However, unlike OpenXR where there is one Session per user, an SuInput Session can have 0 or more Users. Each Session is created from an Application Instance and each Application Instance can only have one Session running at once. Action Set \u00b6 A group of Actions which will be categorised together and enabled or disabled simultaneously. They come it two types: - Static: Immutably attached to Application Instances on their creation. Easiest to use. Can be shared between Application Instances. - Dynamic: Can be edited and added / removed from Application Instances during runtime. Cannot be shared between Application Instances. Every Action Set can have a parent Action Set. If an Action Set has a parent Action Set it is know as an Action Layer and can only be enabled if it's parent Action Set is enabled. Action \u00b6 An abstracted Input / Output endpoint. Each Action has a specific type. e.g. Boolean, Delta2D, LED or Rumble Actions themselves do not have states and can be seen as just labels for the application to efficiently communicate with the runtime. Binding Layout \u00b6 A set of Bindings from one Interaction Profile to several Action Sets.","title":"API Types Summary"},{"location":"API%20Types%20Summary/#runtime","text":"An abstraction over either an embedded or external SuInput runtime and is used to create Instances. There should only be one of these per process.","title":"Runtime"},{"location":"API%20Types%20Summary/#instance","text":"Similar to Vulkan and OpenXR, an Instance is how applications accesses SuInput's API. Since there are already Runtime and Application Instance types it is possible that this abstraction is unnecessary however it could be useful if SuInput ever provides OpenXR-like extensions.","title":"Instance"},{"location":"API%20Types%20Summary/#application","text":"The Application is a structure containing useful metadata about the application such as name and version. It is used by SuInput to group similar Application Instances together.","title":"Application"},{"location":"API%20Types%20Summary/#application-instance","text":"An Application Instance is an (optionally) persistent object containing all the required details about one specific install of an Application. On creation it takes some parameters which become immutable during it's Session's lifespan: - The base Application - Extra metadata specific to this application install - All the Static Action Sets the for the application - All the default Binding Layouts It also has these mutable members: - Dynamic Action Sets - Is installed predicate (Override how the external runtime checks if an app is still installed)","title":"Application Instance"},{"location":"API%20Types%20Summary/#session","text":"An SuInput Session. Similar to OpenXR, a Session is the actual 'running' part of the application. However, unlike OpenXR where there is one Session per user, an SuInput Session can have 0 or more Users. Each Session is created from an Application Instance and each Application Instance can only have one Session running at once.","title":"Session"},{"location":"API%20Types%20Summary/#action-set","text":"A group of Actions which will be categorised together and enabled or disabled simultaneously. They come it two types: - Static: Immutably attached to Application Instances on their creation. Easiest to use. Can be shared between Application Instances. - Dynamic: Can be edited and added / removed from Application Instances during runtime. Cannot be shared between Application Instances. Every Action Set can have a parent Action Set. If an Action Set has a parent Action Set it is know as an Action Layer and can only be enabled if it's parent Action Set is enabled.","title":"Action Set"},{"location":"API%20Types%20Summary/#action","text":"An abstracted Input / Output endpoint. Each Action has a specific type. e.g. Boolean, Delta2D, LED or Rumble Actions themselves do not have states and can be seen as just labels for the application to efficiently communicate with the runtime.","title":"Action"},{"location":"API%20Types%20Summary/#binding-layout","text":"A set of Bindings from one Interaction Profile to several Action Sets.","title":"Binding Layout"},{"location":"Action%20Sets%20and%20Layers/","text":"Every Action an application creates is part of an Action Set. Some of these Actions may also be contained in an Action Layer. Action Sets are groups of actions that can be enabled independently of each other. Action Layers are also groups of actions but they can only be enabled if their parent Action Set is.","title":"Action Sets and Layers"},{"location":"Advanced%20Features/","text":"Multiple Windows \u00b6 Currently Sessions are limited to one window each for simplicities sake when it comes to system cursors and touchscreens System Tree \u00b6 Embedded Runtimes \u00b6 External Runtime \u00b6 Advanced Points \u00b6 Touch screen processor Pressure / Area Cursor History Virtual Touchscreen Controller \u00b6 https://developer.apple.com/videos/play/wwdc2021/10081/ In-App Binding Layout Editing API \u00b6 How do we balance using both the External Editing GUI and an in-game one? Split Screen and Device Sharing \u00b6 How should sharing devices between multiple players work? And how should sharing player focus between applications work?","title":"Advanced Features"},{"location":"Advanced%20Features/#multiple-windows","text":"Currently Sessions are limited to one window each for simplicities sake when it comes to system cursors and touchscreens","title":"Multiple Windows"},{"location":"Advanced%20Features/#system-tree","text":"","title":"System Tree"},{"location":"Advanced%20Features/#embedded-runtimes","text":"","title":"Embedded Runtimes"},{"location":"Advanced%20Features/#external-runtime","text":"","title":"External Runtime"},{"location":"Advanced%20Features/#advanced-points","text":"Touch screen processor Pressure / Area Cursor History","title":"Advanced Points"},{"location":"Advanced%20Features/#virtual-touchscreen-controller","text":"https://developer.apple.com/videos/play/wwdc2021/10081/","title":"Virtual Touchscreen Controller"},{"location":"Advanced%20Features/#in-app-binding-layout-editing-api","text":"How do we balance using both the External Editing GUI and an in-game one?","title":"In-App Binding Layout Editing API"},{"location":"Advanced%20Features/#split-screen-and-device-sharing","text":"How should sharing devices between multiple players work? And how should sharing player focus between applications work?","title":"Split Screen and Device Sharing"},{"location":"Binding%20Layouts/","text":"A Binding Layout is a collection of bindings targeting a specific interaction profile. Application API \u00b6 For every interaction profile an application intends to directly support, it should create and submit at least one default Binding Layout. Default Binding Layouts can only be submitted before the SuInput session has been finalized. While the session is running the application may be able to modify the user's active binding layout. The modifications must be controlled by the user and the submission must only occur due to an explicit action from the user (e.g. clicking an 'Apply' button). Sharing \u00b6 Using the external mapping tool users will be able to export their Binding Layouts to KDL? files. Likewise users will be able to import Binding Layouts. See Conversion#Binding Layout Conversion Quick Settings \u00b6 When creating a Binding Layout the developer can add user adjustable variables called Quick Settings. Quick settings make it easier for users to adjust sensitivity or enable / disable certain bindings, such as Gyro Controls.","title":"Binding Layouts"},{"location":"Binding%20Layouts/#application-api","text":"For every interaction profile an application intends to directly support, it should create and submit at least one default Binding Layout. Default Binding Layouts can only be submitted before the SuInput session has been finalized. While the session is running the application may be able to modify the user's active binding layout. The modifications must be controlled by the user and the submission must only occur due to an explicit action from the user (e.g. clicking an 'Apply' button).","title":"Application API"},{"location":"Binding%20Layouts/#sharing","text":"Using the external mapping tool users will be able to export their Binding Layouts to KDL? files. Likewise users will be able to import Binding Layouts. See Conversion#Binding Layout Conversion","title":"Sharing"},{"location":"Binding%20Layouts/#quick-settings","text":"When creating a Binding Layout the developer can add user adjustable variables called Quick Settings. Quick settings make it easier for users to adjust sensitivity or enable / disable certain bindings, such as Gyro Controls.","title":"Quick Settings"},{"location":"Binding/","text":"Every action can have zero or more bindings per user. If an action has multiple bindings they will be combined according to the action type. If action has zero bindings the action is marked as inactive letting the application know that it will not be used. The application can use the inactive value to enable / disable features such as aim assist (if a Delta2D Turn action is bound) or quick time events (if a quick time event key is unbound). Input Components are bound to Input Actions using bindings . Bindings can be very simple, such as directly binding a Button component to a Boolean action. But they can also be complex, like binding a Scroll Wheel to that same Boolean action or binding Gyro Motion to Delta2D . Binding types (WIP) \u00b6 Instead of creating 'one binding abstraction to rule them all' SuInput uses a system that allows multiple 'binding engines' to work together. As the binding system is the most complex part of SuInput it is almost impossible to cover every scenario with one monolithic system. For example it would be challenging to bend the default engine to allow input from MIDI devices. Default Engine \u00b6 The default engine covers all the conversions listed in Input Component Types and should be enough for most use cases. While I believe it offers a better alternative to many other binding engines, it still has a few major flaws. Strong Points \u00b6 Provides a Input Component based bindings and a simplistic structure Supports most use cases through its 6 step system: 1. Input Component Config 2. Chords 3. Input Component Conversion 4. Activators (if applicable) 5. Action Conversion 6. Action Config Flaws \u00b6 6 step system can be limiting for some conversions e.g. Touchpad -> Joystick -> Spin -> Bool (Debounced) -> Value (Static) is this ICC (Touchpad -> Joystick -> Spin) -> AC (Bool (Debounced) -> Value (Static)) or ICC (Touchpad -> Joystick -> Spin -> Bool (Debounced)) -> AC (-> Value (Static)) or ICC (Touchpad -> Joystick -> Spin) -> ?(Bool (Debounced)) -> AC (-> Value (Static)) Possible Fixes \u00b6 We could ditch the 6 step system for a simpler one: 1. Input Component Config 2. Chords 3. Magic! 6. Action Config All the binding UI would need to do is find some permutation that can convert from Component to Action. The foreseeable downsides of this are: performance overhead, API complexity and configuration complexity. Input Component Config (Sharable) Chords <- needs to exist for all bindings for mode shifting Magic! <- this is where the binding engine lives Action Config 2 passes 1. Priority check pass 2. Actual pass API \u00b6 OnInteractionProfileConnected(interaction_profile: &InteractionProfile, id: u64) OnInteractionProfileDisconnected(interaction_profile: &InteractionProfile, id: u64) OnComponentUpated(interaction_profile_state: &InteractionProfileState, component: (SuPath, SuPath), new_state: ComponentEvent) Binding to Actions \u00b6 Allow binding to actions for ease of use e.g. In Minecraft bind sprint to \"move\".\"forward\" with double tap activator In Generic FPS bind zoom turn to \"turn\" with 0.x sensitivity This means that if the user changes the binding to \"move.forward\" or the binding / sensitivity of \"turn\" they don't need to also change the sprint binding / zoom turn binding / sensitivity Priority still matters here so if an active action is bound to a lower priority action it blocks it from receiving any input. TODO Figure out why this is allowed to break the 6/4 step rule","title":"Binding"},{"location":"Binding/#binding-types-wip","text":"Instead of creating 'one binding abstraction to rule them all' SuInput uses a system that allows multiple 'binding engines' to work together. As the binding system is the most complex part of SuInput it is almost impossible to cover every scenario with one monolithic system. For example it would be challenging to bend the default engine to allow input from MIDI devices.","title":"Binding types (WIP)"},{"location":"Binding/#default-engine","text":"The default engine covers all the conversions listed in Input Component Types and should be enough for most use cases. While I believe it offers a better alternative to many other binding engines, it still has a few major flaws.","title":"Default Engine"},{"location":"Binding/#strong-points","text":"Provides a Input Component based bindings and a simplistic structure Supports most use cases through its 6 step system: 1. Input Component Config 2. Chords 3. Input Component Conversion 4. Activators (if applicable) 5. Action Conversion 6. Action Config","title":"Strong Points"},{"location":"Binding/#flaws","text":"6 step system can be limiting for some conversions e.g. Touchpad -> Joystick -> Spin -> Bool (Debounced) -> Value (Static) is this ICC (Touchpad -> Joystick -> Spin) -> AC (Bool (Debounced) -> Value (Static)) or ICC (Touchpad -> Joystick -> Spin -> Bool (Debounced)) -> AC (-> Value (Static)) or ICC (Touchpad -> Joystick -> Spin) -> ?(Bool (Debounced)) -> AC (-> Value (Static))","title":"Flaws"},{"location":"Binding/#possible-fixes","text":"We could ditch the 6 step system for a simpler one: 1. Input Component Config 2. Chords 3. Magic! 6. Action Config All the binding UI would need to do is find some permutation that can convert from Component to Action. The foreseeable downsides of this are: performance overhead, API complexity and configuration complexity. Input Component Config (Sharable) Chords <- needs to exist for all bindings for mode shifting Magic! <- this is where the binding engine lives Action Config 2 passes 1. Priority check pass 2. Actual pass","title":"Possible Fixes"},{"location":"Binding/#api","text":"OnInteractionProfileConnected(interaction_profile: &InteractionProfile, id: u64) OnInteractionProfileDisconnected(interaction_profile: &InteractionProfile, id: u64) OnComponentUpated(interaction_profile_state: &InteractionProfileState, component: (SuPath, SuPath), new_state: ComponentEvent)","title":"API"},{"location":"Binding/#binding-to-actions","text":"Allow binding to actions for ease of use e.g. In Minecraft bind sprint to \"move\".\"forward\" with double tap activator In Generic FPS bind zoom turn to \"turn\" with 0.x sensitivity This means that if the user changes the binding to \"move.forward\" or the binding / sensitivity of \"turn\" they don't need to also change the sprint binding / zoom turn binding / sensitivity Priority still matters here so if an active action is bound to a lower priority action it blocks it from receiving any input. TODO Figure out why this is allowed to break the 6/4 step rule","title":"Binding to Actions"},{"location":"Conversion/","text":"Binding Layout Conversion \u00b6 If a developer only has access to an Xbox 360 controller when making their game, and thusly only adds Xbox 360 controller binding layouts, we don't want the user to have to create their own Binding Layout from scratch if they are using a different type of controller. Because of this the external remapper provides a tool to automatically convert a binding layout from one Interaction Profile to another. This process is entirely data-driven and can go through multiple stages e.g. Xbox 360 -> Generic Controller -> Dualshock 3. Device Type Coercion \u00b6 That's all well and good for when the user can use the external runtime to modify the converted Binding Layout but what about when the user does not have it active? This is where Device Type coercion is used. In the above example the Dualshock 3 controller would just pretend to be an Xbox 360 controller (it's glyphs would remain DS3 however). For users this should be far easier to understand and use at the cost of loosing device specific features. Device Type coercion also allows devices of different types to be aggregated in the same interaction profile. This makes co-pilot setups easier for users with two different controller types. Co-pilot with different device types is possible without coercion, it just requires creating a binding layout per device type. Device Type coercion is also useful when dealing with controllers of the same family. A controller family is a group of multiple controllers with similar layouts / features. Families \u00b6 Xbox: - Xbox 360 - Xbox One - Xbox One Series SX Dualshock Touchpad: - Dualshock 4 - Dualshock 5 Switch Pro: - Switch Pro Controller - Dual Joycons Oculus Touch: - Oculus Touch CV1 - Oculus Touch Rift S - Oculus Touch Quest","title":"Conversion"},{"location":"Conversion/#binding-layout-conversion","text":"If a developer only has access to an Xbox 360 controller when making their game, and thusly only adds Xbox 360 controller binding layouts, we don't want the user to have to create their own Binding Layout from scratch if they are using a different type of controller. Because of this the external remapper provides a tool to automatically convert a binding layout from one Interaction Profile to another. This process is entirely data-driven and can go through multiple stages e.g. Xbox 360 -> Generic Controller -> Dualshock 3.","title":"Binding Layout Conversion"},{"location":"Conversion/#device-type-coercion","text":"That's all well and good for when the user can use the external runtime to modify the converted Binding Layout but what about when the user does not have it active? This is where Device Type coercion is used. In the above example the Dualshock 3 controller would just pretend to be an Xbox 360 controller (it's glyphs would remain DS3 however). For users this should be far easier to understand and use at the cost of loosing device specific features. Device Type coercion also allows devices of different types to be aggregated in the same interaction profile. This makes co-pilot setups easier for users with two different controller types. Co-pilot with different device types is possible without coercion, it just requires creating a binding layout per device type. Device Type coercion is also useful when dealing with controllers of the same family. A controller family is a group of multiple controllers with similar layouts / features.","title":"Device Type Coercion"},{"location":"Conversion/#families","text":"Xbox: - Xbox 360 - Xbox One - Xbox One Series SX Dualshock Touchpad: - Dualshock 4 - Dualshock 5 Switch Pro: - Switch Pro Controller - Dual Joycons Oculus Touch: - Oculus Touch CV1 - Oculus Touch Rift S - Oculus Touch Quest","title":"Families"},{"location":"Drivers/","text":"All input and output in SuInput is handled via one or more drivers. There are multiple types of drivers, most can be initialized by the external runtime while one must be initialized by the application. Instance Driver \u00b6 e.g. OpenXR / Steam Input device handling ~~The one required driver is known as a Window Driver this driver is the sole responsibility of the application and cannot be updated by the external runtime (with some exceptions). Because of this developers must make sure to implement the driver correctly as the external runtime won't be able to correct them. The Window Driver is responsible for passing all data to SuInput which it cannot access through other Drivers and there should be one Window Driver per runtime (OpenXR applications do not need Window Drivers). ~~TODO make a list of needed events for each target ~~To make implementing a Window Driver easier SuInput provides Framework Window Drivers and Hooking Window Drivers. Framework drivers take raw events from either the OS or established Window Libraries (e.g. SDL2 or GLFW) and processes them for SuInput. Hooking Drivers use OS hooks to access low level events but are not available on many platforms and may need permissions to run. These Window Drivers can be updated by the external runtime. SuInput may ignore some events from the Window Driver if it has a better method of accessing a certain type of event. For example on Windows SuInput will ignore Keyboard and Mouse events from the Window Driver as it can better access this through Raw Input. Generic Driver \u00b6 Zero or more Generic Drivers can be added to a runtime. A Generic Driver provides one or more device types for SuInput. If the user has an external runtime installed, application embedded Generic Drivers will be ignored by SuInput and replaced with the external runtime's equivalents. The Generic Driver must register itself for a device type before it can create any instances of that type. It either registers the type as TOTAL or SUPLIMENTAL, if more than one driver registers itself as TOTAL only devices from one TOTAL driver will be accepted. TODO Prevent multiple SUPLIMENTAL drivers colliding Provided Window Drivers \u00b6 TODO Provided Generic Drivers \u00b6 Win32 Raw Input \u00b6 Event Based Devices: Mouse, Keyboard, System Cursor Standard Interaction profiles: Mouse, Keyboard and Cursor Keyboard Only Linux XInput2 \u00b6 Event Based Devices: Mouse, Keyboard, System Cursor Standard Interaction profiles: Mouse, Keyboard and Cursor Keyboard Only SDL2 \u00b6 Event / Polling Based Devices: All SDL supported controllers Standard Interaction Profiles: Dualshock 4 DualSense Xbox 360 (XInput / sdl2 generic gamepad) Xbox One Switch Pro Joy-Con Pair Left Joy-Con Right Joy-Con GameCube Generic Joystick Features: Gyro, Accelerometer, Rumble, HD Rumble, LED, Player Number, Touch Points, Adaptive Triggers, Microphone, Speaker, Cursor, IR Wii \u00b6 Event Based Devices: Wiimote Wii Nunchuck Classic Controller Classic Controller Pro Standard Interaction Profiles: Wiimote Wiimote + Nunchuck Wiimote + Classic Controller Wiimote + Classic Controller Pro Features: Gyro, Accelerometer, Rumble, Cursor, Speaker, IR OpenXR (Monado?) \u00b6 Polling based Devices: - Standard Interaction profiles: OpenXR interaction profiles Features: XrPose, Gyro, Accelerometer, HD Rumble Kinect \u00b6 (https://twitter.com/SamNChiet/status/1475654581367435265) Eyegaze? \u00b6 Simulation rigs? \u00b6 Analogue Keyboards (Wooting)? \u00b6 NDA Drivers? (PS5, Switch, etc.) \u00b6 Steam Input? \u00b6 STT? \u00b6 Razer Chroma? \u00b6 Logitech Gamepanel? \u00b6 Logitech G-Key? \u00b6 Logitech LED? \u00b6 Logitech Steering Wheel? \u00b6 Artemis? \u00b6 OpenRGB? \u00b6","title":"Drivers"},{"location":"Drivers/#instance-driver","text":"e.g. OpenXR / Steam Input device handling ~~The one required driver is known as a Window Driver this driver is the sole responsibility of the application and cannot be updated by the external runtime (with some exceptions). Because of this developers must make sure to implement the driver correctly as the external runtime won't be able to correct them. The Window Driver is responsible for passing all data to SuInput which it cannot access through other Drivers and there should be one Window Driver per runtime (OpenXR applications do not need Window Drivers). ~~TODO make a list of needed events for each target ~~To make implementing a Window Driver easier SuInput provides Framework Window Drivers and Hooking Window Drivers. Framework drivers take raw events from either the OS or established Window Libraries (e.g. SDL2 or GLFW) and processes them for SuInput. Hooking Drivers use OS hooks to access low level events but are not available on many platforms and may need permissions to run. These Window Drivers can be updated by the external runtime. SuInput may ignore some events from the Window Driver if it has a better method of accessing a certain type of event. For example on Windows SuInput will ignore Keyboard and Mouse events from the Window Driver as it can better access this through Raw Input.","title":"Instance Driver"},{"location":"Drivers/#generic-driver","text":"Zero or more Generic Drivers can be added to a runtime. A Generic Driver provides one or more device types for SuInput. If the user has an external runtime installed, application embedded Generic Drivers will be ignored by SuInput and replaced with the external runtime's equivalents. The Generic Driver must register itself for a device type before it can create any instances of that type. It either registers the type as TOTAL or SUPLIMENTAL, if more than one driver registers itself as TOTAL only devices from one TOTAL driver will be accepted. TODO Prevent multiple SUPLIMENTAL drivers colliding","title":"Generic Driver"},{"location":"Drivers/#provided-window-drivers","text":"TODO","title":"Provided Window Drivers"},{"location":"Drivers/#provided-generic-drivers","text":"","title":"Provided Generic Drivers"},{"location":"Drivers/#win32-raw-input","text":"Event Based Devices: Mouse, Keyboard, System Cursor Standard Interaction profiles: Mouse, Keyboard and Cursor Keyboard Only","title":"Win32 Raw Input"},{"location":"Drivers/#linux-xinput2","text":"Event Based Devices: Mouse, Keyboard, System Cursor Standard Interaction profiles: Mouse, Keyboard and Cursor Keyboard Only","title":"Linux XInput2"},{"location":"Drivers/#sdl2","text":"Event / Polling Based Devices: All SDL supported controllers Standard Interaction Profiles: Dualshock 4 DualSense Xbox 360 (XInput / sdl2 generic gamepad) Xbox One Switch Pro Joy-Con Pair Left Joy-Con Right Joy-Con GameCube Generic Joystick Features: Gyro, Accelerometer, Rumble, HD Rumble, LED, Player Number, Touch Points, Adaptive Triggers, Microphone, Speaker, Cursor, IR","title":"SDL2"},{"location":"Drivers/#wii","text":"Event Based Devices: Wiimote Wii Nunchuck Classic Controller Classic Controller Pro Standard Interaction Profiles: Wiimote Wiimote + Nunchuck Wiimote + Classic Controller Wiimote + Classic Controller Pro Features: Gyro, Accelerometer, Rumble, Cursor, Speaker, IR","title":"Wii"},{"location":"Drivers/#openxr-monado","text":"Polling based Devices: - Standard Interaction profiles: OpenXR interaction profiles Features: XrPose, Gyro, Accelerometer, HD Rumble","title":"OpenXR (Monado?)"},{"location":"Drivers/#kinect","text":"(https://twitter.com/SamNChiet/status/1475654581367435265)","title":"Kinect"},{"location":"Drivers/#eyegaze","text":"","title":"Eyegaze?"},{"location":"Drivers/#simulation-rigs","text":"","title":"Simulation rigs?"},{"location":"Drivers/#analogue-keyboards-wooting","text":"","title":"Analogue Keyboards (Wooting)?"},{"location":"Drivers/#nda-drivers-ps5-switch-etc","text":"","title":"NDA Drivers? (PS5, Switch, etc.)"},{"location":"Drivers/#steam-input","text":"","title":"Steam Input?"},{"location":"Drivers/#stt","text":"","title":"STT?"},{"location":"Drivers/#razer-chroma","text":"","title":"Razer Chroma?"},{"location":"Drivers/#logitech-gamepanel","text":"","title":"Logitech Gamepanel?"},{"location":"Drivers/#logitech-g-key","text":"","title":"Logitech G-Key?"},{"location":"Drivers/#logitech-led","text":"","title":"Logitech LED?"},{"location":"Drivers/#logitech-steering-wheel","text":"","title":"Logitech Steering Wheel?"},{"location":"Drivers/#artemis","text":"","title":"Artemis?"},{"location":"Drivers/#openrgb","text":"","title":"OpenRGB?"},{"location":"Interaction%20Profile/","text":"An Interaction Profile is a collection of one or more devices which will be used together. For example Xbox One Controller , Mouse and Keyboard , and Valve Index Controllers are all standard interaction profiles. Multiple interaction profiles can be used at once to allow for mixed input. However more advanced users can take this further by creating custom interaction profiles. For example two mice, or a DualSense with floor pedals and back buttons. Binding Layouts targeting a certain interaction profile can be automatically converted to other compatible interaction profiles. For example, if an application only has default bindings for an Xbox 360 controller SuInput will be able to convert those bindings to target almost any other generic controller. Once the bindings have been converted they can be edited as if they targeted the other interaction profile. See Conversion#Binding Layout Conversion . Interaction profiles are also in command of what input glyphs the game uses. Profile Assignment \u00b6 Automatic \u00b6 Due to complexities with how mice and keyboards work, they are all aggregated into one interaction profile instance. Game controllers are each assigned their own interaction profile. Game controller extensions (e.g. Wiimote Nunchucks) are combined with their parent controller into one interaction profile. All OpenXR devices are placed into the same interaction profile that the API provides. Applications can 'suggest' which interaction profile instance should be assigned to each player (users can override this using the external runtime), by default one profile each is given to every player. Manual \u00b6 Using the external runtime users can create / modify interaction profiles, assign devices to different interaction profiles and assign interaction profiles to players. For simplicity mice and keyboards are still aggregated however the user can disable this. Semantic Profiles \u00b6 TODO Explain what these are and flesh them out Gameplay Semantic Profile \u00b6 Delta2D, Turn Camera / Move Cursor (Mouse Delta, XInput Right Thumbstick) Axis2D, Move (WASD, XInput Left Thumbstick) Button, Attack (Mouse Left, XInput Right Trigger) Button, Use (Mouse Right, XInput Left Trigger) Button, Reload ('R', XInput 'X') Button, Jump (Space, XInput 'A') Button, Crouch (Ctrl, XInput 'B') Button, Sprint (Shift, XInput Left Thumbstick Click) Button, Menu (Escape, XInput Start) Button, Item Right (Scroll Up, XInput Right Bumper) Button, Item Left (Scroll Down, XInput Left Bumper) GUI Semantic Profile \u00b6 Delta2D, Scroll (Scroll wheel) Delta1D, Zoom (Trackpad Pinch, Ctrl + Scroll wheel) Button, Up (Up Key, XInput DPad Up, XInput Left Thumbstick Up) Button, Left (Left Key, XInput DPad Left, XInput Left Thumbstick Left) Button, Down (Down Key, XInput DPad Down, XInput Left Thumbstick Down) Button, Right (Right Key, XInput DPad Right, XInput Left Thumbstick Right) Button, Select (Mouse Left, Enter, XInput 'A') Button, Back (Backspace, XInput 'B') Button, Exit (Escape, XInput Menu) Button, Tab Right ('E', XInput Right Bumper) Button, Tab Left ('Q', XInput Left Bumper) Button, Menu Right ('D', XInput Right Trigger) Button, Menu Left ('A', XInput Left Trigger) TODO automatic layout generation Mixed Input \u00b6 Sharing \u00b6 Copilot \u00b6 Custom Interaction Profile \u00b6","title":"Interaction Profile"},{"location":"Interaction%20Profile/#profile-assignment","text":"","title":"Profile Assignment"},{"location":"Interaction%20Profile/#automatic","text":"Due to complexities with how mice and keyboards work, they are all aggregated into one interaction profile instance. Game controllers are each assigned their own interaction profile. Game controller extensions (e.g. Wiimote Nunchucks) are combined with their parent controller into one interaction profile. All OpenXR devices are placed into the same interaction profile that the API provides. Applications can 'suggest' which interaction profile instance should be assigned to each player (users can override this using the external runtime), by default one profile each is given to every player.","title":"Automatic"},{"location":"Interaction%20Profile/#manual","text":"Using the external runtime users can create / modify interaction profiles, assign devices to different interaction profiles and assign interaction profiles to players. For simplicity mice and keyboards are still aggregated however the user can disable this.","title":"Manual"},{"location":"Interaction%20Profile/#semantic-profiles","text":"TODO Explain what these are and flesh them out","title":"Semantic Profiles"},{"location":"Interaction%20Profile/#gameplay-semantic-profile","text":"Delta2D, Turn Camera / Move Cursor (Mouse Delta, XInput Right Thumbstick) Axis2D, Move (WASD, XInput Left Thumbstick) Button, Attack (Mouse Left, XInput Right Trigger) Button, Use (Mouse Right, XInput Left Trigger) Button, Reload ('R', XInput 'X') Button, Jump (Space, XInput 'A') Button, Crouch (Ctrl, XInput 'B') Button, Sprint (Shift, XInput Left Thumbstick Click) Button, Menu (Escape, XInput Start) Button, Item Right (Scroll Up, XInput Right Bumper) Button, Item Left (Scroll Down, XInput Left Bumper)","title":"Gameplay Semantic Profile"},{"location":"Interaction%20Profile/#gui-semantic-profile","text":"Delta2D, Scroll (Scroll wheel) Delta1D, Zoom (Trackpad Pinch, Ctrl + Scroll wheel) Button, Up (Up Key, XInput DPad Up, XInput Left Thumbstick Up) Button, Left (Left Key, XInput DPad Left, XInput Left Thumbstick Left) Button, Down (Down Key, XInput DPad Down, XInput Left Thumbstick Down) Button, Right (Right Key, XInput DPad Right, XInput Left Thumbstick Right) Button, Select (Mouse Left, Enter, XInput 'A') Button, Back (Backspace, XInput 'B') Button, Exit (Escape, XInput Menu) Button, Tab Right ('E', XInput Right Bumper) Button, Tab Left ('Q', XInput Left Bumper) Button, Menu Right ('D', XInput Right Trigger) Button, Menu Left ('A', XInput Left Trigger) TODO automatic layout generation","title":"GUI Semantic Profile"},{"location":"Interaction%20Profile/#mixed-input","text":"","title":"Mixed Input"},{"location":"Interaction%20Profile/#sharing","text":"","title":"Sharing"},{"location":"Interaction%20Profile/#copilot","text":"","title":"Copilot"},{"location":"Interaction%20Profile/#custom-interaction-profile","text":"","title":"Custom Interaction Profile"},{"location":"Output/","text":"The output portion of SuInput is extremely WIP as the vast majority of work has been focused on creating a strong input abstraction. Should output actions have explicit types like LED or Rumble Vibration, or should they have more generic types like boolean and float? (with the complex haptic stuff done in the binding similar to input) See: Brilliant idea about haptic output should work LED \u00b6 HD Vibration \u00b6 Rumble Vibration \u00b6 Wheel Force Feedback \u00b6 Player Number \u00b6 Adaptive Trigger \u00b6 Speaker? \u00b6 Rich Status Data \u00b6 For fancy RGB setups (e.g. Artemis ) Or configurable Discord presence?","title":"Output"},{"location":"Output/#led","text":"","title":"LED"},{"location":"Output/#hd-vibration","text":"","title":"HD Vibration"},{"location":"Output/#rumble-vibration","text":"","title":"Rumble Vibration"},{"location":"Output/#wheel-force-feedback","text":"","title":"Wheel Force Feedback"},{"location":"Output/#player-number","text":"","title":"Player Number"},{"location":"Output/#adaptive-trigger","text":"","title":"Adaptive Trigger"},{"location":"Output/#speaker","text":"","title":"Speaker?"},{"location":"Output/#rich-status-data","text":"For fancy RGB setups (e.g. Artemis ) Or configurable Discord presence?","title":"Rich Status Data"},{"location":"Resources/","text":"Bibles \u00b6 https://specialeffectdevkit.info/ http://gyrowiki.jibbsmart.com/ Remapping tools \u00b6 https://github.com/Electronicks/JoyShockMapper https://partner.steamgames.com/doc/features/steam_controller https://help.rewasd.com/ https://andersmalmgren.github.io/FreePIE/ Prior Art \u00b6 https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html#input https://docs.unrealengine.com/5.0/en-US/GameplayFeatures/EnhancedInput/ https://docs.unity3d.com/Packages/com.unity.inputsystem@1.3/manual/KnownLimitations.html","title":"Resources"},{"location":"Resources/#bibles","text":"https://specialeffectdevkit.info/ http://gyrowiki.jibbsmart.com/","title":"Bibles"},{"location":"Resources/#remapping-tools","text":"https://github.com/Electronicks/JoyShockMapper https://partner.steamgames.com/doc/features/steam_controller https://help.rewasd.com/ https://andersmalmgren.github.io/FreePIE/","title":"Remapping tools"},{"location":"Resources/#prior-art","text":"https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html#input https://docs.unrealengine.com/5.0/en-US/GameplayFeatures/EnhancedInput/ https://docs.unity3d.com/Packages/com.unity.inputsystem@1.3/manual/KnownLimitations.html","title":"Prior Art"},{"location":"Scripting/","text":"TODO Reasoning TODO Languages? WASM? Lua? JS? TODO Cheating TODO Framework TODO Workshop","title":"Scripting"},{"location":"Input%20Specific/Button%20Activators/","text":"Button activators are a method of binding multiple actions to one button. Some types of activator can block and interrupt each other. If an activator is marked as blockable it will not fire until SuInput knows the input could not trigger any higher priority activators (e.g. a double tap activator will only fire after the triple tap duration ends). If an activator is marked as interruptible it will be interrupted if a higher priority activator starts (e.g. a double tap activator would be interrupted by a third tap). Button Activator Types \u00b6 Hold: Default functionality Press 1 : Activated for an instant on press Release 1 : Activated for an instant on release Quick Tap: Activated for an instant after quick press and release Double Tap: Activated by two taps or tap then hold Triple Tap: Activated by three taps or two taps then hold Long hold: Activates after being held for a short duration Button Activator Settings \u00b6 Hold \u00b6 #Is this activator blockable by other activators Override behaviour: Block, Interrupt, None (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default) Quick Tap \u00b6 #Is this activator blockable by double tap / tripple tap activators Override behaviour: Block (default), None #Can this activator override hold activators Blocking: True, False (default) #How quickly must the button be released Max Hold Duration: 150 ms (default) Double Tap \u00b6 #Is this activator blockable by tripple tap activators Override behaviour: Block, Interrupt, None (default) #Can this activator override hold activators Blocking: True (default), False #How quickly must the button be double pressed Double Tap Duration: 300 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default) Triple Tap \u00b6 #Can this activator override hold activators Blocking: True (default), False #How quickly must the button be tripple pressed Tripple Tap Duration: 450 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default) Long Hold \u00b6 #How long must the button be held Min Hold Duration: 150 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default) TODO Activators for other types? TODO Are Combos boolean activators? Press / Release activators are equivalent to Hold activators with the matching Impulse setting \u21a9 \u21a9","title":"Button Activators"},{"location":"Input%20Specific/Button%20Activators/#button-activator-types","text":"Hold: Default functionality Press 1 : Activated for an instant on press Release 1 : Activated for an instant on release Quick Tap: Activated for an instant after quick press and release Double Tap: Activated by two taps or tap then hold Triple Tap: Activated by three taps or two taps then hold Long hold: Activates after being held for a short duration","title":"Button Activator Types"},{"location":"Input%20Specific/Button%20Activators/#button-activator-settings","text":"","title":"Button Activator Settings"},{"location":"Input%20Specific/Button%20Activators/#hold","text":"#Is this activator blockable by other activators Override behaviour: Block, Interrupt, None (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default)","title":"Hold"},{"location":"Input%20Specific/Button%20Activators/#quick-tap","text":"#Is this activator blockable by double tap / tripple tap activators Override behaviour: Block (default), None #Can this activator override hold activators Blocking: True, False (default) #How quickly must the button be released Max Hold Duration: 150 ms (default)","title":"Quick Tap"},{"location":"Input%20Specific/Button%20Activators/#double-tap","text":"#Is this activator blockable by tripple tap activators Override behaviour: Block, Interrupt, None (default) #Can this activator override hold activators Blocking: True (default), False #How quickly must the button be double pressed Double Tap Duration: 300 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default)","title":"Double Tap"},{"location":"Input%20Specific/Button%20Activators/#triple-tap","text":"#Can this activator override hold activators Blocking: True (default), False #How quickly must the button be tripple pressed Tripple Tap Duration: 450 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default)","title":"Triple Tap"},{"location":"Input%20Specific/Button%20Activators/#long-hold","text":"#How long must the button be held Min Hold Duration: 150 ms (default) #Should we fire as an impulse Impulse: On Press, On Release, False (default) TODO Activators for other types? TODO Are Combos boolean activators? Press / Release activators are equivalent to Hold activators with the matching Impulse setting \u21a9 \u21a9","title":"Long Hold"},{"location":"Input%20Specific/Child%20Actions/","text":"Actions created with certain Input Action Types will spawn several Child Actions . Child Action bindings are combined with their sibling's and the parent Action's in various ways to create the final action state the application sees. For example, an Axis2D action called Move would have 6 child actions and could be bound to Left Stick on controller. It's child Value actions North, East, South, and West could be renamed to Forward, Right, Back, Left and bound to W, D, S, A accordingly. In future users may be able to add custom Child Action types to an action to combine bindings in a unique way. Sticky Boolean \u00b6 Boolean, Sticky Press Boolean, Sticky Release Boolean, Sticky Toggle Axis1D \u00b6 Value, Positive (Application renamable) Value, Negative (Application renamable) Axis2D \u00b6 Value, North (Application renamable) Value, East (Application renamable) Value, South (Application renamable) Value, West (Application renamable) Axis1D, Vertical (Application renamable) Axis1D, Horizontal (Application renamable) Delta2D \u00b6 Delta1D, Vertical (Application renamable) Delta1D, Horizontal (Application renamable) Cursor \u00b6 Delta2D, Move Delta1D, Vertical Move Delta1D, Horizontal Move","title":"Child Actions"},{"location":"Input%20Specific/Child%20Actions/#sticky-boolean","text":"Boolean, Sticky Press Boolean, Sticky Release Boolean, Sticky Toggle","title":"Sticky Boolean"},{"location":"Input%20Specific/Child%20Actions/#axis1d","text":"Value, Positive (Application renamable) Value, Negative (Application renamable)","title":"Axis1D"},{"location":"Input%20Specific/Child%20Actions/#axis2d","text":"Value, North (Application renamable) Value, East (Application renamable) Value, South (Application renamable) Value, West (Application renamable) Axis1D, Vertical (Application renamable) Axis1D, Horizontal (Application renamable)","title":"Axis2D"},{"location":"Input%20Specific/Child%20Actions/#delta2d","text":"Delta1D, Vertical (Application renamable) Delta1D, Horizontal (Application renamable)","title":"Delta2D"},{"location":"Input%20Specific/Child%20Actions/#cursor","text":"Delta2D, Move Delta1D, Vertical Move Delta1D, Horizontal Move","title":"Cursor"},{"location":"Input%20Specific/Chords%20And%20Combos/","text":"Chords and Shortcuts Combos are very similar, typically both being called shortcuts instead of having unique names. Chords \u00b6 Chords are the more popular form. For example {CTRL+S} and {CTRL+ALT+DEL} are both chords. One or more modifier inputs (e.g. CTRL, ALT, SHIFT) must be held before one command input (e.g. S, DEL) is triggered. The modifier inputs must be buttons but the command input can be any type. By default, every modifier key must be held before the command key, but this behaviour can be configured. These are also an applicable alternative to Steam Input's Mode Shift setting. Combos \u00b6 Combos are more niche than chords and only support Button inputs / outputs making them similar to Button Activators . A combo requires each input being triggered at roughly the same time to activate.","title":"Chords And Combos"},{"location":"Input%20Specific/Chords%20And%20Combos/#chords","text":"Chords are the more popular form. For example {CTRL+S} and {CTRL+ALT+DEL} are both chords. One or more modifier inputs (e.g. CTRL, ALT, SHIFT) must be held before one command input (e.g. S, DEL) is triggered. The modifier inputs must be buttons but the command input can be any type. By default, every modifier key must be held before the command key, but this behaviour can be configured. These are also an applicable alternative to Steam Input's Mode Shift setting.","title":"Chords"},{"location":"Input%20Specific/Chords%20And%20Combos/#combos","text":"Combos are more niche than chords and only support Button inputs / outputs making them similar to Button Activators . A combo requires each input being triggered at roughly the same time to activate.","title":"Combos"},{"location":"Input%20Specific/Input%20Action%20Types/","text":"Primitive Input Types \u00b6 Event? \u00b6 A type of boolean action that only produces events On poll it returns the number of times it has been activated Boolean \u00b6 Repeat presses? TODO On or Off Input Examples: Mouse Button, Keyboard Key Action Examples: Jump, Sprint, Use item Combination: OR every value Output: If the action type is sticky the application can unstick it Value \u00b6 Range: 0 \u2264 x \u22641 Input Examples: Trigger, Analog Keyboard Key Action Examples: Move Forward, Vehicle Accelerate Combination: Binding with greatest value Axis1D \u00b6 Range: -1 \u2264 x \u2264 1 Input Examples: Steering Wheel, Volume Dial Action Examples: Steer Vehicle, Move (2D side-scroller) Combination: Binding with greatest absolute value Axis2D \u00b6 Range: -1 \u2264 x \u2264 1 and -1 \u2264 y \u2264 1 Input Examples: Joystick Action Examples: Move Combination: Binding with greatest length Delta1D \u00b6 Input Examples: 1D Scroll Wheel, Volume Wheel Action Examples: Scroll 1D, Zoom, Adjust Volume, Turn VR Combination: SUM of every value Usage Note: If the application is using the Delta1D action to turn the camera its state must be interpreted as degrees. Delta2D \u00b6 Input Examples: Mouse, Treadmill, Trackball, 2D Scroll Wheel Action Examples: Turn Camera, Walk, Scroll Combination: SUM of every value Usage Note: If the application is using the Delta2D action to turn the camera its state must be interpreted as degrees. Complex Input Types \u00b6 Cursor \u00b6 Input Examples: System Cursor, Wiimote IR sensor Action Examples: Menu Cursor, Free Moving Crosshair, Radial Menu? Combination: Latest moved cursor Data: The normalized position of the cursor inside the application's window. Output: The application can set the position of the cursor and the cursor texture Usage Note: The application MUST use this to access and set the position of the hardware cursor unless necessary, this is to seamlessly enable the usage of a software cursor Wheel \u00b6 Input Examples: Simulation Wheel Combination: Binding with greatest rotation Data: The absolute angle of the wheel in degrees and the range of the wheel (e.g. 180\u00b0 or 900\u00b0) XrPose \u00b6 Input Examples: XR Controller Combination: First active binding Data: Absolute position, orientation, velocity and acceleration in a specific OpenXR coordinate space Gyro \u00b6 Input Examples: XR Controller, Smartphone, Modern Game Controller Combination: First active binding Data: Calibrated angular velocity and best guess orientation Accelerometer \u00b6 Input Examples: XR Controller, Smartphone, Modern Game Controller Combination: First active binding Data: Local acceleration and best guess gravity direction TouchPoints \u00b6 Input Examples: Touchscreen, Touchpad Combination: Binding with most active points / latest changed Data: TODO Magnometer? \u00b6 Microphone? \u00b6 Hybrid Action Types \u00b6 Takes more action state out of the application's hands. By doing this the runtime can enable more complex functionality with little extra effort from the developer. Hotbar \u00b6 Input Examples: Stick shift Action Examples: Item hotbar, Gear selection Combination: Latest changed binding An action with N states, marked as boolean child actions. One of these child actions is marked as 'selected' at any given time. It has two other child actions called Shift Positive and Shift Negative which shift the selected index accordingly. The application can mark one state as default and whether shifting should wrap around. Sticky Boolean \u00b6 Input Examples: N / A Action Examples: Aim down sights, Sprint, Couch Combination: Boolean child OR Sticky state Player Orientation \u00b6 Delta2D Euler angles / Quaternion Reset View","title":"Input Action Types"},{"location":"Input%20Specific/Input%20Action%20Types/#primitive-input-types","text":"","title":"Primitive Input Types"},{"location":"Input%20Specific/Input%20Action%20Types/#event","text":"A type of boolean action that only produces events On poll it returns the number of times it has been activated","title":"Event?"},{"location":"Input%20Specific/Input%20Action%20Types/#boolean","text":"Repeat presses? TODO On or Off Input Examples: Mouse Button, Keyboard Key Action Examples: Jump, Sprint, Use item Combination: OR every value Output: If the action type is sticky the application can unstick it","title":"Boolean"},{"location":"Input%20Specific/Input%20Action%20Types/#value","text":"Range: 0 \u2264 x \u22641 Input Examples: Trigger, Analog Keyboard Key Action Examples: Move Forward, Vehicle Accelerate Combination: Binding with greatest value","title":"Value"},{"location":"Input%20Specific/Input%20Action%20Types/#axis1d","text":"Range: -1 \u2264 x \u2264 1 Input Examples: Steering Wheel, Volume Dial Action Examples: Steer Vehicle, Move (2D side-scroller) Combination: Binding with greatest absolute value","title":"Axis1D"},{"location":"Input%20Specific/Input%20Action%20Types/#axis2d","text":"Range: -1 \u2264 x \u2264 1 and -1 \u2264 y \u2264 1 Input Examples: Joystick Action Examples: Move Combination: Binding with greatest length","title":"Axis2D"},{"location":"Input%20Specific/Input%20Action%20Types/#delta1d","text":"Input Examples: 1D Scroll Wheel, Volume Wheel Action Examples: Scroll 1D, Zoom, Adjust Volume, Turn VR Combination: SUM of every value Usage Note: If the application is using the Delta1D action to turn the camera its state must be interpreted as degrees.","title":"Delta1D"},{"location":"Input%20Specific/Input%20Action%20Types/#delta2d","text":"Input Examples: Mouse, Treadmill, Trackball, 2D Scroll Wheel Action Examples: Turn Camera, Walk, Scroll Combination: SUM of every value Usage Note: If the application is using the Delta2D action to turn the camera its state must be interpreted as degrees.","title":"Delta2D"},{"location":"Input%20Specific/Input%20Action%20Types/#complex-input-types","text":"","title":"Complex Input Types"},{"location":"Input%20Specific/Input%20Action%20Types/#cursor","text":"Input Examples: System Cursor, Wiimote IR sensor Action Examples: Menu Cursor, Free Moving Crosshair, Radial Menu? Combination: Latest moved cursor Data: The normalized position of the cursor inside the application's window. Output: The application can set the position of the cursor and the cursor texture Usage Note: The application MUST use this to access and set the position of the hardware cursor unless necessary, this is to seamlessly enable the usage of a software cursor","title":"Cursor"},{"location":"Input%20Specific/Input%20Action%20Types/#wheel","text":"Input Examples: Simulation Wheel Combination: Binding with greatest rotation Data: The absolute angle of the wheel in degrees and the range of the wheel (e.g. 180\u00b0 or 900\u00b0)","title":"Wheel"},{"location":"Input%20Specific/Input%20Action%20Types/#xrpose","text":"Input Examples: XR Controller Combination: First active binding Data: Absolute position, orientation, velocity and acceleration in a specific OpenXR coordinate space","title":"XrPose"},{"location":"Input%20Specific/Input%20Action%20Types/#gyro","text":"Input Examples: XR Controller, Smartphone, Modern Game Controller Combination: First active binding Data: Calibrated angular velocity and best guess orientation","title":"Gyro"},{"location":"Input%20Specific/Input%20Action%20Types/#accelerometer","text":"Input Examples: XR Controller, Smartphone, Modern Game Controller Combination: First active binding Data: Local acceleration and best guess gravity direction","title":"Accelerometer"},{"location":"Input%20Specific/Input%20Action%20Types/#touchpoints","text":"Input Examples: Touchscreen, Touchpad Combination: Binding with most active points / latest changed Data: TODO","title":"TouchPoints"},{"location":"Input%20Specific/Input%20Action%20Types/#magnometer","text":"","title":"Magnometer?"},{"location":"Input%20Specific/Input%20Action%20Types/#microphone","text":"","title":"Microphone?"},{"location":"Input%20Specific/Input%20Action%20Types/#hybrid-action-types","text":"Takes more action state out of the application's hands. By doing this the runtime can enable more complex functionality with little extra effort from the developer.","title":"Hybrid Action Types"},{"location":"Input%20Specific/Input%20Action%20Types/#hotbar","text":"Input Examples: Stick shift Action Examples: Item hotbar, Gear selection Combination: Latest changed binding An action with N states, marked as boolean child actions. One of these child actions is marked as 'selected' at any given time. It has two other child actions called Shift Positive and Shift Negative which shift the selected index accordingly. The application can mark one state as default and whether shifting should wrap around.","title":"Hotbar"},{"location":"Input%20Specific/Input%20Action%20Types/#sticky-boolean","text":"Input Examples: N / A Action Examples: Aim down sights, Sprint, Couch Combination: Boolean child OR Sticky state","title":"Sticky Boolean"},{"location":"Input%20Specific/Input%20Action%20Types/#player-orientation","text":"Delta2D Euler angles / Quaternion Reset View","title":"Player Orientation"},{"location":"Input%20Specific/Input%20Component%20Types/","text":"S -> Simple M -> Medium 'Normal' A -> Advanced Button (Boolean) \u00b6 Component Conversions None Activators: Button Activators Action Conversions S: Button -> Boolean S: Button -> Value M: Button -> Axis1D M: Button -> Axis2D M: Button -> Delta1D M: Button -> Delta2D M: Button -> Cursor Trigger / Analog Key (Value) \u00b6 Component Conversions S: Trigger -> Button (soft pull, full pull, zones) M: Trigger -> Cursor Action Conversions S: Trigger -> Value Joystick (Axis2D) \u00b6 Component Conversions S: Joystick -> Button (Sector) S: Joystick -> Trigger (Sector) M: Joystick -> Move1D (Spin) M: Joystick -> Trigger (Length) M: Joystick -> Button (Zone) M: Joystick -> Cursor M: Joystick -> Button (Radial Menu) Action Conversions S: Joystick -> Axis2D M: Joystick -> Delta1D (Flickstick) S: Joystick -> Delta2D Move1D (Delta1D) \u00b6 Component Conversions None Action Conversions S: Move1D -> Delta1D S: Move1D -> Boolean (Fire debounced impulses on input) Move2D (Delta2D) \u00b6 Component Conversions M: Move2D -> Move1D (Split directions) A: Move2D -> Button (Gestures) Action Conversions S: Move2D -> Delta2D S: Move1D -> Boolean (Fire debounced impulses on input) Touchpad (Touch Points) \u00b6 Component Conversions S: Touchpad -> Move2D (Drag) S: Touchpad -> Button (Touch, Swipe, Gesture, Zones) S: Touchpad -> Move1D (Pinch, Gesture) S: Touchpad -> Joystick M: Touchpad -> Cursor M: Touchpad -> Button (Radial Menu) Action Conversions S: Touchpad -> Touch Points Cursor \u00b6 Component Conversions None Action Conversions S: Cursor -> Touch Points S: Cursor -> Cursor Motion (Combined Gyro + Accel) \u00b6 Component Conversions M: Motion -> Button (Lean, Shake, Thrust) M: Motion -> Trigger (Lean, Shake, Thrust) M: Motion -> Move2D (As Mouse) M: Motion -> Axis1D (As Wheel) Action Conversions S: Motion -> Gyro (Orientation) S: Motion -> Acceleration (Gravity) TODO Touchscreen \u00b6","title":"Input Component Types"},{"location":"Input%20Specific/Input%20Component%20Types/#button-boolean","text":"Component Conversions None Activators: Button Activators Action Conversions S: Button -> Boolean S: Button -> Value M: Button -> Axis1D M: Button -> Axis2D M: Button -> Delta1D M: Button -> Delta2D M: Button -> Cursor","title":"Button (Boolean)"},{"location":"Input%20Specific/Input%20Component%20Types/#trigger-analog-key-value","text":"Component Conversions S: Trigger -> Button (soft pull, full pull, zones) M: Trigger -> Cursor Action Conversions S: Trigger -> Value","title":"Trigger / Analog Key (Value)"},{"location":"Input%20Specific/Input%20Component%20Types/#joystick-axis2d","text":"Component Conversions S: Joystick -> Button (Sector) S: Joystick -> Trigger (Sector) M: Joystick -> Move1D (Spin) M: Joystick -> Trigger (Length) M: Joystick -> Button (Zone) M: Joystick -> Cursor M: Joystick -> Button (Radial Menu) Action Conversions S: Joystick -> Axis2D M: Joystick -> Delta1D (Flickstick) S: Joystick -> Delta2D","title":"Joystick (Axis2D)"},{"location":"Input%20Specific/Input%20Component%20Types/#move1d-delta1d","text":"Component Conversions None Action Conversions S: Move1D -> Delta1D S: Move1D -> Boolean (Fire debounced impulses on input)","title":"Move1D (Delta1D)"},{"location":"Input%20Specific/Input%20Component%20Types/#move2d-delta2d","text":"Component Conversions M: Move2D -> Move1D (Split directions) A: Move2D -> Button (Gestures) Action Conversions S: Move2D -> Delta2D S: Move1D -> Boolean (Fire debounced impulses on input)","title":"Move2D (Delta2D)"},{"location":"Input%20Specific/Input%20Component%20Types/#touchpad-touch-points","text":"Component Conversions S: Touchpad -> Move2D (Drag) S: Touchpad -> Button (Touch, Swipe, Gesture, Zones) S: Touchpad -> Move1D (Pinch, Gesture) S: Touchpad -> Joystick M: Touchpad -> Cursor M: Touchpad -> Button (Radial Menu) Action Conversions S: Touchpad -> Touch Points","title":"Touchpad (Touch Points)"},{"location":"Input%20Specific/Input%20Component%20Types/#cursor","text":"Component Conversions None Action Conversions S: Cursor -> Touch Points S: Cursor -> Cursor","title":"Cursor"},{"location":"Input%20Specific/Input%20Component%20Types/#motion-combined-gyro-accel","text":"Component Conversions M: Motion -> Button (Lean, Shake, Thrust) M: Motion -> Trigger (Lean, Shake, Thrust) M: Motion -> Move2D (As Mouse) M: Motion -> Axis1D (As Wheel) Action Conversions S: Motion -> Gyro (Orientation) S: Motion -> Acceleration (Gravity)","title":"Motion (Combined Gyro + Accel)"},{"location":"Input%20Specific/Input%20Component%20Types/#todo-touchscreen","text":"","title":"TODO Touchscreen"},{"location":"Input%20Specific/Input%20Glyphs/","text":"Since Applications are mostly unaware of what devices the user is using, they should query SuInput for a user friendly message or an image to describe an action's bindings. Stylized Glyphs \u00b6 Some Games will want to provide their own glyphs to better match their art style. To do this they can request the paths for the bindings to a certain action. SuInput will only return paths of interaction profiles that the application has created binding layouts for. Paths will be of the format /interaction_profile/.../user/.../input/... However using the external runtime the user will be able to overrule this behaviour and force the application to use SuInput's glyphs. This is done for users who may struggle to make out stylized glyphs for a multitude of reasons such as poor vision or display quality. Overlay? \u00b6 If an application missuses the system users could enable an overlay which gives a better description of bindings for the active actions?","title":"Input Glyphs"},{"location":"Input%20Specific/Input%20Glyphs/#stylized-glyphs","text":"Some Games will want to provide their own glyphs to better match their art style. To do this they can request the paths for the bindings to a certain action. SuInput will only return paths of interaction profiles that the application has created binding layouts for. Paths will be of the format /interaction_profile/.../user/.../input/... However using the external runtime the user will be able to overrule this behaviour and force the application to use SuInput's glyphs. This is done for users who may struggle to make out stylized glyphs for a multitude of reasons such as poor vision or display quality.","title":"Stylized Glyphs"},{"location":"Input%20Specific/Input%20Glyphs/#overlay","text":"If an application missuses the system users could enable an overlay which gives a better description of bindings for the active actions?","title":"Overlay?"},{"location":"Input%20Specific/Text/","text":"Common \u00b6 Type CKJ Locale override No Learn Spell check Auto Complete Auto Format Private Textbox \u00b6 Cursor Multi-Select Multi-Line Text-Steaming Content Name Max-Len Autocomplete Single Word Password (Hide Content) Non-Textbox (Callback) \u00b6 Has Arrow Keys Copy / Cut / Paste VR Specific \u00b6 Bounding box Touchscreen Specific \u00b6 Obscured area https://developer.android.com/training/keyboard-input https://developer.apple.com/library/archive/documentation/StringsTextFonts/Conceptual/TextAndWebiPhoneOS/KeyboardManagement/KeyboardManagement.html https://www.w3schools.com/tags/tag_input.asp","title":"Text"},{"location":"Input%20Specific/Text/#common","text":"Type CKJ Locale override No Learn Spell check Auto Complete Auto Format Private","title":"Common"},{"location":"Input%20Specific/Text/#textbox","text":"Cursor Multi-Select Multi-Line Text-Steaming Content Name Max-Len Autocomplete Single Word Password (Hide Content)","title":"Textbox"},{"location":"Input%20Specific/Text/#non-textbox-callback","text":"Has Arrow Keys Copy / Cut / Paste","title":"Non-Textbox (Callback)"},{"location":"Input%20Specific/Text/#vr-specific","text":"Bounding box","title":"VR Specific"},{"location":"Input%20Specific/Text/#touchscreen-specific","text":"Obscured area https://developer.android.com/training/keyboard-input https://developer.apple.com/library/archive/documentation/StringsTextFonts/Conceptual/TextAndWebiPhoneOS/KeyboardManagement/KeyboardManagement.html https://www.w3schools.com/tags/tag_input.asp","title":"Touchscreen Specific"},{"location":"Internal/Device%20Lifecycle/","text":"On Device Connect \u00b6 Driver registers device, specifying its parent and if the parent's name should change If device does not have siblings: (for now this is always true) If external runtime is installed a pop-up asks if this device is a new player or should be added to an existing player If no external runtime: Ask game which player device should go to, by default the device will go to either the first player without a controller or player 1. If the device is a Mouse or Keyboard it will always go to player 1 If the device has siblings: (for now this is always false) If the siblings are not bound to a player then just log a connect message If the siblings are bound to a player but are in custom bundles or std bundles with coercion then log If the siblings are bound to a player in a standard bundle with no coercion then ask player if upgrade bundle to accept new device If player declines then device does not get added to player If player accepts then standard bundle gets upgraded to new device bundle yadayada Then changes to bundles have to be propagated Since device changes don't happen that often its fine to just destroy the old interaction profiles and rebuild them. This looses all Binding State so we may want to implement a better way in future On Device Disconnect \u00b6 Alert Game Alert Player Remember Device for a few in case it gets reconnected","title":"Device Lifecycle"},{"location":"Internal/Device%20Lifecycle/#on-device-connect","text":"Driver registers device, specifying its parent and if the parent's name should change If device does not have siblings: (for now this is always true) If external runtime is installed a pop-up asks if this device is a new player or should be added to an existing player If no external runtime: Ask game which player device should go to, by default the device will go to either the first player without a controller or player 1. If the device is a Mouse or Keyboard it will always go to player 1 If the device has siblings: (for now this is always false) If the siblings are not bound to a player then just log a connect message If the siblings are bound to a player but are in custom bundles or std bundles with coercion then log If the siblings are bound to a player in a standard bundle with no coercion then ask player if upgrade bundle to accept new device If player declines then device does not get added to player If player accepts then standard bundle gets upgraded to new device bundle yadayada Then changes to bundles have to be propagated Since device changes don't happen that often its fine to just destroy the old interaction profiles and rebuild them. This looses all Binding State so we may want to implement a better way in future","title":"On Device Connect"},{"location":"Internal/Device%20Lifecycle/#on-device-disconnect","text":"Alert Game Alert Player Remember Device for a few in case it gets reconnected","title":"On Device Disconnect"},{"location":"Internal/Driver%20Interface/","text":"Input Events \u00b6 The driver tells the runtime about changes in state through Input Events Motion and Pose \u00b6 Types of Motion and Pose components: - Accelerometer -> Acceleration, can be used to guess gravity direction - Gyroscope -> Angular Velocity, may require calibration - Magnetometer -> Orientation, missing from many devices and often low quality - Pose -> Position, Orientation and Velocities, typically only provided by XR devices Accelerometer Gyroscope Magnetometer \u00b6 These are three simple sensors used for approximating a device's kinetic state. SuInput assumes that the values of all three sensors will be local to the device's transformation and that the units are m/s 2 , Gs and \u03bcT accordingly. TODO should angular velocity be in radians at the driver level? TODO should accelerometer data really be in Gs? If a device has one or more of these sensors the runtime uses sensor fusion to extrapolate data. TODO should the driver be able to provide its own sensor fused data Due to sensor fusion if one or more of these sensors are present in a device they should all be updated using one BatchInputUpdate. Otherwise the runtime will run the sensor fusion algorithm for every event with outdated information. However if one or more components have not generated an event it should be ok for the driver to send only the other events as the runtime will just use the previous data. Pose \u00b6 Pose is a highly processed form of component as deterministic position requires input from many complicated systems such as lasers, cameras and magnetic field generators. Due to the high levels of complexity and specialization SuInput leaves all this work to the driver. TODO Figure out how different spaces should be communicated Ownership and Sync \u00b6","title":"Driver Interface"},{"location":"Internal/Driver%20Interface/#input-events","text":"The driver tells the runtime about changes in state through Input Events","title":"Input Events"},{"location":"Internal/Driver%20Interface/#motion-and-pose","text":"Types of Motion and Pose components: - Accelerometer -> Acceleration, can be used to guess gravity direction - Gyroscope -> Angular Velocity, may require calibration - Magnetometer -> Orientation, missing from many devices and often low quality - Pose -> Position, Orientation and Velocities, typically only provided by XR devices","title":"Motion and Pose"},{"location":"Internal/Driver%20Interface/#accelerometer-gyroscope-magnetometer","text":"These are three simple sensors used for approximating a device's kinetic state. SuInput assumes that the values of all three sensors will be local to the device's transformation and that the units are m/s 2 , Gs and \u03bcT accordingly. TODO should angular velocity be in radians at the driver level? TODO should accelerometer data really be in Gs? If a device has one or more of these sensors the runtime uses sensor fusion to extrapolate data. TODO should the driver be able to provide its own sensor fused data Due to sensor fusion if one or more of these sensors are present in a device they should all be updated using one BatchInputUpdate. Otherwise the runtime will run the sensor fusion algorithm for every event with outdated information. However if one or more components have not generated an event it should be ok for the driver to send only the other events as the runtime will just use the previous data.","title":"Accelerometer Gyroscope Magnetometer"},{"location":"Internal/Driver%20Interface/#pose","text":"Pose is a highly processed form of component as deterministic position requires input from many complicated systems such as lasers, cameras and magnetic field generators. Due to the high levels of complexity and specialization SuInput leaves all this work to the driver. TODO Figure out how different spaces should be communicated","title":"Pose"},{"location":"Internal/Driver%20Interface/#ownership-and-sync","text":"","title":"Ownership and Sync"},{"location":"Internal/Pipeline/","text":"When an input event enters the pipeline it can cause zero or more events at every stage. These events need to be cleaned up / processed by their creators once they have been used and can sometimes be fed back into the same system. As the input backend increases in complexity we could end up adding more systems and connections between systems. Since we will be dealing with relatively few events I don't think there is any need for multithreading though the kind of pipeline I want to design should be fairly easy to parallelize. Input Component Event \u00b6 Boolean: IsPressed bool Delta2D: Delta (f64, f64) Cursor: Position (f64, f64), Window: Option<WND> ## Action Event Boolean= IsPressed: bool, Changed: bool Delta2D= Delta: (f64, f64) Cursor= Position: (f64, f64), Window: Option<WND> ## Action State Boolean= IsPressed: bool, Changed: bool Delta2D= Delta(f64, f64) Cursor= Position: (f64, f64), Window: Option<WND> Device state changes or continuous state is polled Driver sends an input event to the runtime (the driver may apply some calibration) The runtime applies extra calibration to the input event (custom dead zones / gyro) The runtime updates the cached device state The runtime sends an event to all interaction profiles the device is in aggregation The interaction profile sends an event to all users using the interaction profile The user sends an event to every binding layout targeting the interaction profile The binding layout sends an event to every binding targeting the updated component The bindings are executed The binding layout sends an event to the user for every action event aggregation The user updates its action state and sends an event to its session Device / Interaction Profile Graph \u00b6 Device \u00b6 A device is the lowest common factor of a collection of input / output components. LCF meaning that a DualSense would be one device and a Wiimote and Nunchuck would be two devices since a Wiimote can exist without the Nunchuck's components and visa versa. However some device components can just be listed as optional for simplicities sake. For example the gyro component of the Wiimote is just listed as optional instead of having an extra device for Motion Plus. Device Bundle \u00b6 A collection of devices which optionally expose a Bundle Interaction Profile Custom Bundles -> Two Xbox controllers Standard Bundles -> Left + Right Joycons Interaction Profile \u00b6 An interaction profile is the final stage of components which a Binding Layout actually interacts with. The binding layout is not aware of what types of devices are actually backing the interaction profile, apart from when it is choosing Input Glyphs to display. Bundle Interaction Profile \u00b6 External runtime only Standard Interaction Profile \u00b6 User paths and such","title":"Pipeline"},{"location":"Internal/Pipeline/#input-component-event","text":"Boolean: IsPressed bool Delta2D: Delta (f64, f64) Cursor: Position (f64, f64), Window: Option<WND> ## Action Event Boolean= IsPressed: bool, Changed: bool Delta2D= Delta: (f64, f64) Cursor= Position: (f64, f64), Window: Option<WND> ## Action State Boolean= IsPressed: bool, Changed: bool Delta2D= Delta(f64, f64) Cursor= Position: (f64, f64), Window: Option<WND> Device state changes or continuous state is polled Driver sends an input event to the runtime (the driver may apply some calibration) The runtime applies extra calibration to the input event (custom dead zones / gyro) The runtime updates the cached device state The runtime sends an event to all interaction profiles the device is in aggregation The interaction profile sends an event to all users using the interaction profile The user sends an event to every binding layout targeting the interaction profile The binding layout sends an event to every binding targeting the updated component The bindings are executed The binding layout sends an event to the user for every action event aggregation The user updates its action state and sends an event to its session","title":"Input Component Event"},{"location":"Internal/Pipeline/#device-interaction-profile-graph","text":"","title":"Device / Interaction Profile Graph"},{"location":"Internal/Pipeline/#device","text":"A device is the lowest common factor of a collection of input / output components. LCF meaning that a DualSense would be one device and a Wiimote and Nunchuck would be two devices since a Wiimote can exist without the Nunchuck's components and visa versa. However some device components can just be listed as optional for simplicities sake. For example the gyro component of the Wiimote is just listed as optional instead of having an extra device for Motion Plus.","title":"Device"},{"location":"Internal/Pipeline/#device-bundle","text":"A collection of devices which optionally expose a Bundle Interaction Profile Custom Bundles -> Two Xbox controllers Standard Bundles -> Left + Right Joycons","title":"Device Bundle"},{"location":"Internal/Pipeline/#interaction-profile","text":"An interaction profile is the final stage of components which a Binding Layout actually interacts with. The binding layout is not aware of what types of devices are actually backing the interaction profile, apart from when it is choosing Input Glyphs to display.","title":"Interaction Profile"},{"location":"Internal/Pipeline/#bundle-interaction-profile","text":"External runtime only","title":"Bundle Interaction Profile"},{"location":"Internal/Pipeline/#standard-interaction-profile","text":"User paths and such","title":"Standard Interaction Profile"},{"location":"Internal/Platforms/","text":"Platforms \u00b6 Summary \u00b6 Name Specialized Driver External Runtime Win32 Hooking \ud83d\udea7 DLL Loading \u274c Linux Hooking \u274c SO Loading \u274c MacOS Hooking \u274c Dylib Loading? \u274c UWP Hooking? \u274c WASM / IPC? \u274c Android Hooking? \u274c External Service? \u274c IOS Unknown \u274c Against ToS ( for now? )\u274c Web Hooking \u274c WASM? \u274c PlayStation 4 Unknown \u274c Unknown \u274c PlayStation 5 Unknown \u274c Unknown \u274c Switch Unknown \u274c Unknown \u274c Xbox GDK Unknown \u274c Unknown \u274c Hooking drivers don't require any extra work by the developer and just work (unless they conflict with the game engine). Manual drivers require developers to pass certain events to the platform driver, because of this it is unlikely they can be used with closed-source engines such as Unity. In the case that a hooking driver is not available and the developer cannot access low level OS events, the developer can create a custom driver that takes events from the game engine and feeds them to the runtime. This is the approach that will be used for the Unity, Unreal and Godot plugins on platforms with missing drivers. Win32 \u00b6 Keyboard and mouse: Raw Input (Per process singleton leading to conflicts in some engines) Cursor and Text: Hooks Controllers: SDL2 (Xbox controllers require process being in focus) Touch: TODO Win32 / UWP \u00b6 The GameInput API is coming to Win32 and UWP soon and is supposed to deprecate Raw Input and the APIs SDL2 uses, however it requires process focus? and is a per process singleton making injection into engines annoying. https://docs.microsoft.com/en-us/gaming/gdk/_content/gc/reference/input/gameinput/enums/gameinputfocuspolicy???? https://docs.microsoft.com/en-us/gaming/gdk/_content/gc/input/overviews/input-fundamentals#application-focus???? https://github.com/microsoft/GDK/issues/11 Linux \u00b6 Keyboard and mouse: XInput2 Cursor and Text: TODO Controllers: SDL2 Touch: TODO MacOS \u00b6 Keyboard and mouse: Event Taps Cursor and Text: TODO Controllers: SDL2 Touch: TODO Web \u00b6 Keyboard and mouse: UI Events Cursor and Text: UI Events Controllers: Gamepad API (suffers from weak API and implementations) Touch: Touch Events Android \u00b6 Oh boy Android development is split into two favours: java + jni and pure native Thankfully most existing game engines use the more hackable java + jni approach. From what testing I've done it seems possible to add an empty ViewGroup to the front of the Activity's main window and by returning false on all the event callbacks the events should get passed down to whatever the game engine uses to read input (e.g. Activity events or Surface listeners) If this doesn't work for whatever reason we can do something similar to Monado and place a transparent window over all the Activity's other windows. Then we can manually trigger the Activity's events from our event callbacks. I think this only works for Java + JNI Activities though so something different will be needed for pure native ones. Many of these game engines also expose a method for the game developers to add code the the Main Activity so in a worst case scenario we could just tell the devs which functions to override. It should be trivial to inject a text input widget to receive textbox input.","title":"Platforms"},{"location":"Internal/Platforms/#platforms","text":"","title":"Platforms"},{"location":"Internal/Platforms/#summary","text":"Name Specialized Driver External Runtime Win32 Hooking \ud83d\udea7 DLL Loading \u274c Linux Hooking \u274c SO Loading \u274c MacOS Hooking \u274c Dylib Loading? \u274c UWP Hooking? \u274c WASM / IPC? \u274c Android Hooking? \u274c External Service? \u274c IOS Unknown \u274c Against ToS ( for now? )\u274c Web Hooking \u274c WASM? \u274c PlayStation 4 Unknown \u274c Unknown \u274c PlayStation 5 Unknown \u274c Unknown \u274c Switch Unknown \u274c Unknown \u274c Xbox GDK Unknown \u274c Unknown \u274c Hooking drivers don't require any extra work by the developer and just work (unless they conflict with the game engine). Manual drivers require developers to pass certain events to the platform driver, because of this it is unlikely they can be used with closed-source engines such as Unity. In the case that a hooking driver is not available and the developer cannot access low level OS events, the developer can create a custom driver that takes events from the game engine and feeds them to the runtime. This is the approach that will be used for the Unity, Unreal and Godot plugins on platforms with missing drivers.","title":"Summary"},{"location":"Internal/Platforms/#win32","text":"Keyboard and mouse: Raw Input (Per process singleton leading to conflicts in some engines) Cursor and Text: Hooks Controllers: SDL2 (Xbox controllers require process being in focus) Touch: TODO","title":"Win32"},{"location":"Internal/Platforms/#win32-uwp","text":"The GameInput API is coming to Win32 and UWP soon and is supposed to deprecate Raw Input and the APIs SDL2 uses, however it requires process focus? and is a per process singleton making injection into engines annoying. https://docs.microsoft.com/en-us/gaming/gdk/_content/gc/reference/input/gameinput/enums/gameinputfocuspolicy???? https://docs.microsoft.com/en-us/gaming/gdk/_content/gc/input/overviews/input-fundamentals#application-focus???? https://github.com/microsoft/GDK/issues/11","title":"Win32 / UWP"},{"location":"Internal/Platforms/#linux","text":"Keyboard and mouse: XInput2 Cursor and Text: TODO Controllers: SDL2 Touch: TODO","title":"Linux"},{"location":"Internal/Platforms/#macos","text":"Keyboard and mouse: Event Taps Cursor and Text: TODO Controllers: SDL2 Touch: TODO","title":"MacOS"},{"location":"Internal/Platforms/#web","text":"Keyboard and mouse: UI Events Cursor and Text: UI Events Controllers: Gamepad API (suffers from weak API and implementations) Touch: Touch Events","title":"Web"},{"location":"Internal/Platforms/#android","text":"Oh boy Android development is split into two favours: java + jni and pure native Thankfully most existing game engines use the more hackable java + jni approach. From what testing I've done it seems possible to add an empty ViewGroup to the front of the Activity's main window and by returning false on all the event callbacks the events should get passed down to whatever the game engine uses to read input (e.g. Activity events or Surface listeners) If this doesn't work for whatever reason we can do something similar to Monado and place a transparent window over all the Activity's other windows. Then we can manually trigger the Activity's events from our event callbacks. I think this only works for Java + JNI Activities though so something different will be needed for pure native ones. Many of these game engines also expose a method for the game developers to add code the the Main Activity so in a worst case scenario we could just tell the devs which functions to override. It should be trivial to inject a text input widget to receive textbox input.","title":"Android"},{"location":"Internal/Plugins/","text":"Plugins \u00b6 Summary \u00b6 Name Desktop OpenXR Console Mobile / Quest Unity \u274c \u274c \u274c \u274c Godot \u274c \u274c \u274c \u274c Unreal \u274c \u274c \u274c \u274c OpenXR layer \u274c \u274c N/A ? Bevy \u274c \u274c \u274c \u274c Unity \u00b6 As the most popular game engine supporting Unity is high priority Unity already has a very popular action based input plugin called Rewired. It lacks support for desktop gyro, multiple mice / keyboards, external configuration, advanced binding / activators / chords, VR, etc. However it is well embedded into the Unity ecosystem and very popular, falling back on Unity input for unsupported platforms, written in pure C# for easy porting, player centric input, SDL2 fallback, etc. Hooking OpenXR looks easy enough https://docs.unity3d.com/Packages/com.unity.xr.openxr@1.4/manual/features.html Godot \u00b6 As the most popular FOSS game engine Godot is high priority The existing Godot input action system seems very limited (no gyro etc) so SuInput should have little competition. The Godot OpenXR plugin is still under heavy development so it should be possible to request some hooks are added to it. Unreal \u00b6 I haven't looked that much into Unreal yet but from what I've seen it should be fairly easy to get Desktop working thanks to hooking. However OpenXR may require forking the engine and modifying the OpenXR plugin, hopefully we will be allowed to merge some features upstream. I have no idea what the Console + Mobile ecosystem looks like. OpenXR Layer \u00b6 While technically not a plugin I think it makes sense to track its progress here The OpenXR Layer shouldn't use the loader and just run from the embedded runtime since it's installed by the external runtime anyway. It should allow controller + desktop input support but it must be configurable and disabled by default because it may clash with the game's existing input solution. It should expose an extension that would allow SuInput installed in the app to communicate with the layer. It may need to go against the spec and be enabled by default because some game engines may make it impossible to request custom extensions. Is it possible to add it to mobile / quest games by injecting into the apk? Create a fake loader that calls the real loader and inject it into the apk. I doubt this will work well for apps installed of the Oculus Store because 'copyright' or whatever but it could work for Sidequest. Bevy \u00b6 Since Bevy is pure rust and extremely modular it should be super easy to develop an SuInput plugin for it","title":"Plugins"},{"location":"Internal/Plugins/#plugins","text":"","title":"Plugins"},{"location":"Internal/Plugins/#summary","text":"Name Desktop OpenXR Console Mobile / Quest Unity \u274c \u274c \u274c \u274c Godot \u274c \u274c \u274c \u274c Unreal \u274c \u274c \u274c \u274c OpenXR layer \u274c \u274c N/A ? Bevy \u274c \u274c \u274c \u274c","title":"Summary"},{"location":"Internal/Plugins/#unity","text":"As the most popular game engine supporting Unity is high priority Unity already has a very popular action based input plugin called Rewired. It lacks support for desktop gyro, multiple mice / keyboards, external configuration, advanced binding / activators / chords, VR, etc. However it is well embedded into the Unity ecosystem and very popular, falling back on Unity input for unsupported platforms, written in pure C# for easy porting, player centric input, SDL2 fallback, etc. Hooking OpenXR looks easy enough https://docs.unity3d.com/Packages/com.unity.xr.openxr@1.4/manual/features.html","title":"Unity"},{"location":"Internal/Plugins/#godot","text":"As the most popular FOSS game engine Godot is high priority The existing Godot input action system seems very limited (no gyro etc) so SuInput should have little competition. The Godot OpenXR plugin is still under heavy development so it should be possible to request some hooks are added to it.","title":"Godot"},{"location":"Internal/Plugins/#unreal","text":"I haven't looked that much into Unreal yet but from what I've seen it should be fairly easy to get Desktop working thanks to hooking. However OpenXR may require forking the engine and modifying the OpenXR plugin, hopefully we will be allowed to merge some features upstream. I have no idea what the Console + Mobile ecosystem looks like.","title":"Unreal"},{"location":"Internal/Plugins/#openxr-layer","text":"While technically not a plugin I think it makes sense to track its progress here The OpenXR Layer shouldn't use the loader and just run from the embedded runtime since it's installed by the external runtime anyway. It should allow controller + desktop input support but it must be configurable and disabled by default because it may clash with the game's existing input solution. It should expose an extension that would allow SuInput installed in the app to communicate with the layer. It may need to go against the spec and be enabled by default because some game engines may make it impossible to request custom extensions. Is it possible to add it to mobile / quest games by injecting into the apk? Create a fake loader that calls the real loader and inject it into the apk. I doubt this will work well for apps installed of the Oculus Store because 'copyright' or whatever but it could work for Sidequest.","title":"OpenXR Layer"},{"location":"Internal/Plugins/#bevy","text":"Since Bevy is pure rust and extremely modular it should be super easy to develop an SuInput plugin for it","title":"Bevy"},{"location":"Internal/Threading/","text":"Off-Thread processing \u00b6 Possible performance improvements / lower latency Action callback is called from the 'working thread' The sync function does nothing Synchronous binding processing (New approach) \u00b6 Action state callbacks are called during a sync call All binding processing takes place during the sync call Input is buffered off-thread, though some drivers may sync during the sync call for lower latency Embedded Runtime Lifecycle: App loads runtime App adds driver Runtime initializes Driver Driver adds device Runtime registers device Driver sends Input Runtime caches input Runtime sends input events to running sessions App creates instance App creates Actions App creates Default Binding Layouts App creates session Runtime syncs session on create Action Sets are disabled by default so not much happens ~~ App gets action state App syncs session Session handles changes in devices Session enables action sets against cached interaction profile state Session disables action sets against cached interaction profile state Session applies cached input events to bindings ~~ Is there a reason why session need devices? Probably needed for outputs Outputs: Streaming Components: e.g. Cursor, Pose -> Device for each component is selected at sync time? Outputs: e.g. Haptic / Vibration -> Device for each component is selected at sync time?","title":"Threading"},{"location":"Internal/Threading/#off-thread-processing","text":"Possible performance improvements / lower latency Action callback is called from the 'working thread' The sync function does nothing","title":"Off-Thread processing"},{"location":"Internal/Threading/#synchronous-binding-processing-new-approach","text":"Action state callbacks are called during a sync call All binding processing takes place during the sync call Input is buffered off-thread, though some drivers may sync during the sync call for lower latency Embedded Runtime Lifecycle: App loads runtime App adds driver Runtime initializes Driver Driver adds device Runtime registers device Driver sends Input Runtime caches input Runtime sends input events to running sessions App creates instance App creates Actions App creates Default Binding Layouts App creates session Runtime syncs session on create Action Sets are disabled by default so not much happens ~~ App gets action state App syncs session Session handles changes in devices Session enables action sets against cached interaction profile state Session disables action sets against cached interaction profile state Session applies cached input events to bindings ~~ Is there a reason why session need devices? Probably needed for outputs Outputs: Streaming Components: e.g. Cursor, Pose -> Device for each component is selected at sync time? Outputs: e.g. Haptic / Vibration -> Device for each component is selected at sync time?","title":"Synchronous binding processing (New approach)"},{"location":"Internal/Working%20User/","text":"Things the Working User needs to know about an action: Its state: Used for generating events and polling Its type: Used for storing state in a well typed manner Its enabled state: Used for telling binding layouts if an action's set is enabled Its priority: Used by binding layouts for choosing if bindings should be overridden Its hierarchical position and id: Used for combining it with its children / siblings and parent Its handle: For quick identification","title":"Working User"}]}